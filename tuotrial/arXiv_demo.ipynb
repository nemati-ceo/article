{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6b831a",
   "metadata": {},
   "source": [
    "# PaperFlow: Complete Academic Paper Processing Demo\n",
    "\n",
    "PaperFlow is a unified pipeline for academic paper ingestion, extraction, and RAG (Retrieval-Augmented Generation). It allows you to:\n",
    "\n",
    "- **Search** across multiple academic sources (arXiv, PubMed, Semantic Scholar, OpenAlex)\n",
    "- **Download** PDFs automatically\n",
    "- **Extract** text and structure from PDFs\n",
    "- **Chunk** content for RAG applications\n",
    "- **Embed** and store in vector databases\n",
    "- **Query** papers using natural language\n",
    "\n",
    "## Features\n",
    "\n",
    "- ðŸ” Multi-source search (arXiv, PubMed, Semantic Scholar, OpenAlex)\n",
    "- ðŸ“¥ Automatic PDF downloading\n",
    "- ðŸ“„ Advanced PDF text extraction (Marker AI, Docling, MarkItDown)\n",
    "- âœ‚ï¸ Intelligent text chunking\n",
    "- ðŸ§  Vector embeddings for RAG\n",
    "- ðŸ’¾ ChromaDB integration\n",
    "- ðŸ”— LangChain compatibility\n",
    "- ðŸ“Š Tabular result display\n",
    "- ðŸ’» Command-line interface\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install the latest version of PaperFlow with all optional dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b232fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping paperflow as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall paperflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea2353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting paperflow[extraction-all,providers,rag]\n",
      "  Downloading paperflow-0.1.11-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (2.12.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (0.28.1)\n",
      "Requirement already satisfied: arxiv>=2.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (2.3.1)\n",
      "Requirement already satisfied: biopython>=1.80 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (1.86)\n",
      "Requirement already satisfied: requests>=2.28.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (2.32.5)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (0.9.0)\n",
      "Collecting opentelemetry-api==1.37.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-sdk==1.37.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-proto==1.37.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_proto-1.37.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.37.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: marker-pdf>=0.2.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (1.10.1)\n",
      "Requirement already satisfied: markitdown>=0.1.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from paperflow[extraction-all,providers,rag]) (0.1.4)\n",
      "Requirement already satisfied: docling>=2.0.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from paperflow[extraction-all,providers,rag]) (2.41.0)\n",
      "Collecting langchain>=0.1.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading langchain-1.2.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting chromadb>=0.4.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading chromadb-1.4.0-cp39-abi3-win_amd64.whl.metadata (7.3 kB)\n",
      "Collecting sentence-transformers>=2.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting paperscraper>=0.3.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading paperscraper-0.3.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pyalex>=0.13 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading pyalex-0.19-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting semanticscholar>=0.8.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading semanticscholar-0.11.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api==1.37.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from opentelemetry-api==1.37.0->paperflow[extraction-all,providers,rag]) (4.14.1)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from opentelemetry-proto==1.37.0->paperflow[extraction-all,providers,rag]) (6.33.2)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from arxiv>=2.0.0->paperflow[extraction-all,providers,rag]) (6.0.12)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from feedparser~=6.0.10->arxiv>=2.0.0->paperflow[extraction-all,providers,rag]) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from requests>=2.28.0->paperflow[extraction-all,providers,rag]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from requests>=2.28.0->paperflow[extraction-all,providers,rag]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from requests>=2.28.0->paperflow[extraction-all,providers,rag]) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from requests>=2.28.0->paperflow[extraction-all,providers,rag]) (2026.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from biopython>=1.80->paperflow[extraction-all,providers,rag]) (1.26.4)\n",
      "Collecting build>=1.0.3 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pybase64-1.4.3-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (1.20.1)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (6.0.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading mmh3-5.2.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading orjson-3.11.5-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (1.9.0)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from build>=1.0.3->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from build>=1.0.3->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.4.6)\n",
      "Requirement already satisfied: docling-core<3.0.0,>=2.42.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.42.0)\n",
      "Requirement already satisfied: docling-parse<5.0.0,>=4.0.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (4.1.0)\n",
      "Requirement already satisfied: docling-ibm-models<4,>=3.6.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.8.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.2.0)\n",
      "Requirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (4.30.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.10.1)\n",
      "Requirement already satisfied: huggingface_hub<1,>=0.23 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (0.36.0)\n",
      "Requirement already satisfied: easyocr<2.0,>=1.7 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.7.2)\n",
      "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.4.0)\n",
      "Requirement already satisfied: python-docx<2.0.0,>=1.1.2 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.2.0)\n",
      "Requirement already satisfied: python-pptx<2.0.0,>=1.0.2 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.0.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (4.14.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.3.3)\n",
      "Requirement already satisfied: marko<3.0.0,>=2.1.2 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.1.4)\n",
      "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.1.5)\n",
      "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (5.4.0)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (10.4.0)\n",
      "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.6.0)\n",
      "Requirement already satisfied: pylatexenc<3.0,>=2.10 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.10)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.16.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.5)\n",
      "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.1.0)\n",
      "Requirement already satisfied: latex2mathml<4.0.0,>=3.77.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling-core<3.0.0,>=2.42.0->docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.78.0)\n",
      "Requirement already satisfied: semchunk<3.0.0,>=2.2.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (4.57.3)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.2.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.2.2)\n",
      "Requirement already satisfied: torchvision<1,>=0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (0.17.2)\n",
      "Requirement already satisfied: jsonlines<4.0.0,>=3.1.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.1.0)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (4.11.0.86)\n",
      "Requirement already satisfied: safetensors<1,>=0.4.3 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (0.7.0)\n",
      "Requirement already satisfied: pywin32>=305 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from docling-parse<5.0.0,>=4.0.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (311)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from easyocr<2.0,>=1.7->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (0.26.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from easyocr<2.0,>=1.7->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (0.6.6)\n",
      "Requirement already satisfied: Shapely in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from easyocr<2.0,>=1.7->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.1.1)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from easyocr<2.0,>=1.7->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from easyocr<2.0,>=1.7->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.11.1.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from huggingface_hub<1,>=0.23->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from huggingface_hub<1,>=0.23->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2025.12.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from jsonschema>=4.19.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.28.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from openpyxl<4.0.0,>=3.1.5->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pandas<3.0.0,>=2.1.4->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pydantic>=2.0->paperflow[extraction-all,providers,rag]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pydantic>=2.0->paperflow[extraction-all,providers,rag]) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pydantic>=2.0->paperflow[extraction-all,providers,rag]) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.3.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.2.1)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from python-pptx<2.0.0,>=1.0.2->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.2.5)\n",
      "Requirement already satisfied: mpire[dill] in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2.10.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.42.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from typer>=0.9.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from typer>=0.9.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (1.5.4)\n",
      "Requirement already satisfied: anyio in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from httpx>=0.25.0->paperflow[extraction-all,providers,rag]) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from httpx>=0.25.0->paperflow[extraction-all,providers,rag]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->paperflow[extraction-all,providers,rag]) (0.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (2.45.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.28.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (6.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.6.1)\n",
      "Collecting langchain-core<2.0.0,>=1.2.1 (from langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading langchain_core-1.2.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<2.0.0,>=1.2.1->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.2.1->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading langsmith-0.6.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.2.1->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading uuid_utils-0.12.0-cp39-abi3-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph<1.1.0,>=1.0.2->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading langgraph_sdk-0.3.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading ormsgpack-1.12.1-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain>=0.1.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading zstandard-0.25.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anthropic<0.47.0,>=0.46.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (0.46.0)\n",
      "Requirement already satisfied: ftfy<7.0.0,>=6.1.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (6.3.1)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.56.0)\n",
      "Requirement already satisfied: markdown2<3.0.0,>=2.5.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (2.5.4)\n",
      "Requirement already satisfied: markdownify<2.0.0,>=1.1.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.2.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.65.2 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.109.1)\n",
      "Requirement already satisfied: pdftext<0.7.0,>=0.6.3 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (0.6.3)\n",
      "Requirement already satisfied: pre-commit<5.0.0,>=4.2.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (4.5.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (3.14.3)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.6.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.7.1)\n",
      "Requirement already satisfied: surya-ocr<0.18.0,>=0.17.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (0.17.0)\n",
      "INFO: pip is looking at multiple versions of marker-pdf to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.10.0-py3-none-any.whl.metadata (30 kB)\n",
      "  Downloading marker_pdf-1.9.3-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting surya-ocr<0.17.0,>=0.16.7 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.16.7-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.9.2-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.9.1-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.9.0-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.8.5-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting surya-ocr<0.16.0,>=0.15.4 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.15.4-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.8.4-py3-none-any.whl.metadata (29 kB)\n",
      "INFO: pip is still looking at multiple versions of marker-pdf to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading marker_pdf-1.8.3-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.8.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting surya-ocr<0.15.0,>=0.14.6 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.14.7-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.8.0-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.7.5-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting markdownify<0.14.0,>=0.13.1 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading markdownify-0.13.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.7.4-py3-none-any.whl.metadata (28 kB)\n",
      "  Downloading marker_pdf-1.7.3-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.7.2-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.7.0-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading marker_pdf-1.6.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting surya-ocr<0.14.0,>=0.13.1 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.13.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.6.1-py3-none-any.whl.metadata (27 kB)\n",
      "  Downloading marker_pdf-1.6.0-py3-none-any.whl.metadata (27 kB)\n",
      "  Downloading marker_pdf-1.5.5-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting surya-ocr<0.13.0,>=0.12.0 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.12.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.5.4-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading marker_pdf-1.5.3-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting surya-ocr<0.12.0,>=0.11.1 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.11.1-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.5.2-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting pdftext<0.6.0,>=0.5.1 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pdftext-0.5.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.5.1-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading marker_pdf-1.5.0-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading marker_pdf-1.4.0-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading marker_pdf-1.3.5-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting google-generativeai<0.9.0,>=0.8.3 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading google_generativeai-0.8.6-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting surya-ocr<0.11.0,>=0.10.2 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.10.3-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting texify<0.3.0,>=0.2.1 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading texify-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.3.4-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading marker_pdf-1.3.3-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading marker_pdf-1.3.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting surya-ocr<0.10.0,>=0.9.3 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.9.3-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.3.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading marker_pdf-1.3.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading marker_pdf-1.2.7-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pdftext<0.5.0,>=0.4.1 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pdftext-0.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting surya-ocr<0.9.0,>=0.8.3 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.8.3-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tabled-pdf<0.3.0,>=0.2.0 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading tabled_pdf-0.2.0-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.2.6-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.2.5-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.2.4-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.2.3-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.2.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Downloading marker_pdf-1.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading marker_pdf-1.0.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pdftext<0.4.0,>=0.3.20 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pdftext-0.3.20-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting surya-ocr<0.8.0,>=0.7.0 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.7.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tabled-pdf<0.2.0,>=0.1.5 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading tabled_pdf-0.1.7-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-1.0.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Downloading marker_pdf-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Downloading marker_pdf-0.3.10-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting surya-ocr<0.7.0,>=0.6.13 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.6.13-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.3.9-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.8-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.7-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.6-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.5-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.4-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.3-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.2-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.1-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading marker_pdf-0.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Downloading marker_pdf-0.2.17-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting scikit-learn<=1.4.2,>=1.3.2 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading scikit_learn-1.4.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting surya-ocr<0.6.0,>=0.5.0 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.5.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting texify<0.2.0,>=0.1.10 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading texify-0.1.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from ftfy<7.0.0,>=6.1.1->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (0.2.13)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (25.12.19)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from scikit-learn<=1.4.2,>=1.3.2->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from scikit-learn<=1.4.2,>=1.3.2->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (3.5.0)\n",
      "Collecting opencv-python<5.0.0.0,>=4.9.0.80 (from surya-ocr<0.6.0,>=0.5.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of surya-ocr to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.16-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.15 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.15-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.15-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.14 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.14-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.14-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.12 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.12-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.13-py3-none-any.whl.metadata (14 kB)\n",
      "INFO: pip is still looking at multiple versions of surya-ocr to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading marker_pdf-0.2.12-py3-none-any.whl.metadata (14 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading marker_pdf-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading marker_pdf-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting ray<3.0.0,>=2.20.0 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading ray-2.53.0-cp312-cp312-win_amd64.whl.metadata (23 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.10 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.11-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading surya_ocr-0.4.10-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.9-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.8 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.9-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading surya_ocr-0.4.8-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.7 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.7-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.7-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.6 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.6-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.6-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting surya-ocr<0.5.0,>=0.4.3 (from marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading surya_ocr-0.4.5-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading surya_ocr-0.4.4-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading surya_ocr-0.4.3-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting marker-pdf>=0.2.0 (from paperflow[extraction-all,providers,rag])\n",
      "  Downloading marker_pdf-0.2.5-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading marker_pdf-0.2.4-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading marker_pdf-0.2.2-py3-none-any.whl.metadata (14 kB)\n",
      "  Downloading marker_pdf-0.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting torchvision<1,>=0 (from docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading torchvision-0.24.1-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting torch<3.0.0,>=2.2.2 (from docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4,>=3.6.0->docling>=2.0.0->paperflow[extraction-all,providers,rag]) (80.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from anthropic<0.47.0,>=0.46.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.3.1)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from google-genai<2.0.0,>=1.0.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (15.0.1)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (3.4.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (2.6.10)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in c:\\users\\llmserver\\appdata\\roaming\\python\\python312\\site-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (1.9.1)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from pre-commit<5.0.0,>=4.2.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (20.35.4)\n",
      "Requirement already satisfied: einops<0.9.0,>=0.8.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from surya-ocr<0.18.0,>=0.17.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (0.8.1)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=4.3.6 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from surya-ocr<0.18.0,>=0.17.0->marker-pdf>=0.2.0->paperflow[extraction-all,providers,rag]) (4.5.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from markitdown>=0.1.0->paperflow[extraction-all,providers,rag]) (0.7.1)\n",
      "Requirement already satisfied: magika~=0.6.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from markitdown>=0.1.0->paperflow[extraction-all,providers,rag]) (0.6.3)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pymed-paperscraper>=1.0.4 (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pymed_paperscraper-1.0.5-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting scholarly>=1.0.0 (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading scholarly-1.7.11-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting seaborn (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting matplotlib (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-win_amd64.whl.metadata (52 kB)\n",
      "Collecting matplotlib_venn (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading matplotlib-venn-1.1.2.tar.gz (40 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting bs4 (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting impact-factor>=1.1.1 (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading impact_factor-1.1.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting thefuzz (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytest (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting tldextract (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading tldextract-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting unidecode (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dotenv (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting boto3 (from paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading boto3-1.42.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: pygments in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from impact-factor>=1.1.1->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag]) (2.19.2)\n",
      "Collecting webrequests (from impact-factor>=1.1.1->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading webrequests-1.0.8-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sql_manager (from impact-factor>=1.1.1->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading sql_manager-1.0.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from rich>=10.11.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.4.0->paperflow[extraction-all,providers,rag]) (0.1.2)\n",
      "Collecting arrow (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting bibtexparser (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading bibtexparser-1.4.3.tar.gz (55 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting deprecated (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fake-useragent (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting free-proxy (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading free_proxy-1.1.3.tar.gz (5.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting selenium (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading selenium-4.39.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting sphinx-rtd-theme (from scholarly>=1.0.0->paperscraper>=0.3.0->paperflow[extraction-all,providers,rag])\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: nest_asyncio in c:\\users\\llmserver\\miniconda3\\envs\\article\\lib\\site-packages (from semanticscholar>=0.8.0->paperflow[extraction-all,providers,rag]) (1.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py\", line 174, in version\n",
      "    return parse_version(version)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 200, in __init__\n",
      "    match = self._regex.search(version)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or bytes-like object, got 'NoneType'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 107, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 98, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 85, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 388, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 99, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 601, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 513, in resolve\n",
      "    failure_criterion = self._attempt_to_pin_criterion(name)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 220, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 211, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers\\resolution.py\", line 125, in _add_to_criteria\n",
      "    matches = self._p.find_matches(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\provider.py\", line 268, in find_matches\n",
      "    return self._factory.find_candidates(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 450, in find_candidates\n",
      "    return self._iter_found_candidates(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 341, in _iter_found_candidates\n",
      "    _get_installed_candidate(),\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 284, in _get_installed_candidate\n",
      "    if not specifier.contains(installed_dist.version, prereleases=True):\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\pip\\_internal\\metadata\\importlib\\_dists.py\", line 176, in version\n",
      "    raise BadMetadata(self._dist, reason=\"invalid metadata entry `version`\")\n",
      "pip._internal.metadata.importlib._compat.BadMetadata: Bad metadata in <importlib.metadata.PathDistribution object at 0x000001825441E0F0> (invalid metadata entry `version`)\n"
     ]
    }
   ],
   "source": [
    "!pip install paperflow[extraction-all,rag,providers] --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f859da0",
   "metadata": {},
   "source": [
    "## Demo: All Academic Providers\n",
    "\n",
    "This demo shows how to use **all academic paper providers** in PaperFlow:\n",
    "- ðŸ” **arXiv** - Preprints and technical papers\n",
    "- ðŸ¥ **PubMed** - Biomedical and life sciences research  \n",
    "- ðŸ“š **Semantic Scholar** - AI-powered academic search\n",
    "- ðŸŒ **OpenAlex** - Open catalog of scholarly works\n",
    "\n",
    "The demo covers:\n",
    "1. Search across all providers\n",
    "2. Display results in formatted tables and JSON\n",
    "3. Download PDFs from multiple sources\n",
    "4. Extract text and structure from PDFs (with optional GPU acceleration)\n",
    "5. Prepare content for RAG applications\n",
    "\n",
    "The pipeline separates download and extraction phases for better control and efficiency.\n",
    "\n",
    "## Configuration Options\n",
    "\n",
    "**GPU Support**: If you have a CUDA-compatible GPU, you can enable GPU acceleration for faster PDF extraction:\n",
    "\n",
    "```python\n",
    "USE_GPU = True  # Enable GPU acceleration\n",
    "```\n",
    "\n",
    "**Custom PDF Directory**: Specify where to save downloaded PDFs:\n",
    "\n",
    "```python\n",
    "PDF_DIR = './my_papers'  # Custom directory for PDFs\n",
    "```\n",
    "\n",
    "**PDF Extraction Backend**: Choose the best extraction method for your needs:\n",
    "\n",
    "```python\n",
    "# Options: \"auto\", \"marker\", \"docling\", \"markitdown\"\n",
    "EXTRACTION_BACKEND = \"auto\"  # Auto-select: marker â†’ docling â†’ markitdown\n",
    "# EXTRACTION_BACKEND = \"marker\"      # High quality, best for academic papers\n",
    "# EXTRACTION_BACKEND = \"docling\"     # Good table/figure extraction  \n",
    "# EXTRACTION_BACKEND = \"markitdown\"  # Lightweight, fast, CPU only\n",
    "```\n",
    "\n",
    "**Usage**:\n",
    "```python\n",
    "pipeline = PaperPipeline(\n",
    "    gpu=USE_GPU, \n",
    "    pdf_dir=PDF_DIR,\n",
    "    extraction_backend=EXTRACTION_BACKEND\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6995996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading Marker AI models...\n",
      "âœ… Marker AI loaded\n",
      "Searching for papers on transformers...\n",
      "Found 3 papers in 551ms\n",
      "Sources: ['arxiv']\n",
      "\n",
      "+-----+----------------------------------------+------------------------------+--------+----------+--------------+\n",
      "|   # | Title                                  | Authors                      |   Year | Source   | Link/ID      |\n",
      "+=====+========================================+==============================+========+==========+==============+\n",
      "|   1 | Dilated Neighborhood Attention         | Ali Hassani, Humphrey Shi    |   2022 | arxiv    | 2209.15001v3 |\n",
      "|     | Transformer                            |                              |        |          |              |\n",
      "+-----+----------------------------------------+------------------------------+--------+----------+--------------+\n",
      "|   2 | Mask-Attention-Free Transformer for 3D | Xin Lai, Yuhui Yuan, Ruihang |   2023 | arxiv    | 2309.01692v1 |\n",
      "|     | Instance Segmentation                  | Chu et al.                   |        |          |              |\n",
      "+-----+----------------------------------------+------------------------------+--------+----------+--------------+\n",
      "|   3 | Attention Guided CAM: Visual           | Saebom Leem, Hyunseok Seo    |   2024 | arxiv    | 2402.04563v1 |\n",
      "|     | Explanations of Vision Transfor...     |                              |        |          |              |\n",
      "+-----+----------------------------------------+------------------------------+--------+----------+--------------+\n",
      "\n",
      "Downloading all papers...\n",
      "Downloading paper 1: Dilated Neighborhood Attention Transformer...\n",
      "PDF saved to: test_pdfs\\2209.15001v3.pdf\n",
      "  - PDF saved: test_pdfs\\2209.15001v3.pdf\n",
      "\n",
      "Downloading paper 2: Mask-Attention-Free Transformer for 3D Instance Se...\n",
      "PDF saved to: test_pdfs\\2309.01692v1.pdf\n",
      "  - PDF saved: test_pdfs\\2309.01692v1.pdf\n",
      "\n",
      "Downloading paper 3: Attention Guided CAM: Visual Explanations of Visio...\n",
      "PDF saved to: test_pdfs\\2402.04563v1.pdf\n",
      "  - PDF saved: test_pdfs\\2402.04563v1.pdf\n",
      "\n",
      "Extracting all papers...\n",
      "Extracting paper 1: Dilated Neighborhood Attention Transformer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recognizing Layout: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [01:32<00:00,  5.45s/it]\n",
      "Running OCR Error Detection: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.44it/s]\n",
      "Detecting bboxes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.93s/it]\n",
      "Recognizing Text:  14%|â–ˆâ–        | 51/361 [09:44<34:34,  6.69s/it]   "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, paper \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(papers, \u001b[32m1\u001b[39m):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExtracting paper \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpaper.metadata.title[:\u001b[32m50\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     paper = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m  - Sections: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(paper.sections)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(paper.chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\NAI_Project/paperflow/src\\paperflow\\pipeline.py:259\u001b[39m, in \u001b[36mPaperPipeline.process\u001b[39m\u001b[34m(self, paper, download, extract, chunk, embed, pdf_dir)\u001b[39m\n\u001b[32m    256\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m paper\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extract \u001b[38;5;129;01mand\u001b[39;00m paper.has_pdf:\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     paper = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunk:\n\u001b[32m    262\u001b[39m     paper = \u001b[38;5;28mself\u001b[39m.chunk(paper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\NAI_Project/paperflow/src\\paperflow\\pipeline.py:159\u001b[39m, in \u001b[36mPaperPipeline.extract\u001b[39m\u001b[34m(self, paper)\u001b[39m\n\u001b[32m    156\u001b[39m     paper.status = ProcessingStatus.PENDING\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m paper\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m sections_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m paper.sections = [\n\u001b[32m    161\u001b[39m     Section(**section_data) \u001b[38;5;28;01mfor\u001b[39;00m section_data \u001b[38;5;129;01min\u001b[39;00m sections_dict.values()\n\u001b[32m    162\u001b[39m ]\n\u001b[32m    163\u001b[39m paper.has_sections = \u001b[38;5;28mbool\u001b[39m(paper.sections)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\NAI_Project/paperflow/src\\paperflow\\processors\\marker_processor.py:75\u001b[39m, in \u001b[36mextract_sections\u001b[39m\u001b[34m(self, pdf_path)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     74\u001b[39m     rendered = \u001b[38;5;28mself\u001b[39m._converter(pdf_path)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     full_text, _, _ = \u001b[38;5;28mself\u001b[39m._text_from_rendered(rendered)\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m full_text\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\NAI_Project/paperflow/src\\paperflow\\processors\\marker_processor.py:66\u001b[39m, in \u001b[36mextract_full_text\u001b[39m\u001b[34m(self, pdf_path)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     65\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâŒ Marker AI error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28mself\u001b[39m.available = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\marker\\converters\\pdf.py:195\u001b[39m, in \u001b[36mPdfConverter.__call__\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m | io.BytesIO):\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.filepath_to_str(filepath) \u001b[38;5;28;01mas\u001b[39;00m temp_path:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         document = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28mself\u001b[39m.page_count = \u001b[38;5;28mlen\u001b[39m(document.pages)\n\u001b[32m    197\u001b[39m         renderer = \u001b[38;5;28mself\u001b[39m.resolve_dependencies(\u001b[38;5;28mself\u001b[39m.renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\marker\\converters\\pdf.py:182\u001b[39m, in \u001b[36mPdfConverter.build_document\u001b[39m\u001b[34m(self, filepath)\u001b[39m\n\u001b[32m    180\u001b[39m ocr_builder = \u001b[38;5;28mself\u001b[39m.resolve_dependencies(OcrBuilder)\n\u001b[32m    181\u001b[39m provider = provider_cls(filepath, \u001b[38;5;28mself\u001b[39m.config)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m document = \u001b[43mDocumentBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mocr_builder\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m structure_builder_cls = \u001b[38;5;28mself\u001b[39m.resolve_dependencies(StructureBuilder)\n\u001b[32m    186\u001b[39m structure_builder_cls(document)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\marker\\builders\\document.py:36\u001b[39m, in \u001b[36mDocumentBuilder.__call__\u001b[39m\u001b[34m(self, provider, layout_builder, line_builder, ocr_builder)\u001b[39m\n\u001b[32m     34\u001b[39m line_builder(document, provider)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable_ocr:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mocr_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m document\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\marker\\builders\\ocr.py:87\u001b[39m, in \u001b[36mOcrBuilder.__call__\u001b[39m\u001b[34m(self, document, provider)\u001b[39m\n\u001b[32m     83\u001b[39m pages_to_ocr = [page \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m document.pages \u001b[38;5;28;01mif\u001b[39;00m page.text_extraction_method == \u001b[33m'\u001b[39m\u001b[33msurya\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     84\u001b[39m ocr_page_images, block_polygons, block_ids, block_original_texts = (\n\u001b[32m     85\u001b[39m     \u001b[38;5;28mself\u001b[39m.get_ocr_images_polygons_ids(document, pages_to_ocr, provider)\n\u001b[32m     86\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr_extraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpages_to_ocr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mocr_page_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_polygons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_original_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\marker\\builders\\ocr.py:178\u001b[39m, in \u001b[36mOcrBuilder.ocr_extraction\u001b[39m\u001b[34m(self, document, pages, images, block_polygons, block_ids, block_original_texts)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;28mself\u001b[39m.recognition_model.disable_tqdm = \u001b[38;5;28mself\u001b[39m.disable_tqdm\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m recognition_results: List[OCRResult] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecognition_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mocr_task_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpolygons\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_polygons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_original_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrecognition_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_recognition_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmath_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisable_ocr_math\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_repeated_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdrop_repeated_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_sliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2148\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\n\u001b[32m    189\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(recognition_results) == \u001b[38;5;28mlen\u001b[39m(images) == \u001b[38;5;28mlen\u001b[39m(pages) == \u001b[38;5;28mlen\u001b[39m(block_ids), (\n\u001b[32m    192\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMismatch in OCR lengths: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(recognition_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(pages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(block_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    193\u001b[39m )\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m document_page, page_recognition_result, page_block_ids, image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[32m    195\u001b[39m     pages, recognition_results, block_ids, images\n\u001b[32m    196\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\recognition\\__init__.py:431\u001b[39m, in \u001b[36mRecognitionPredictor.__call__\u001b[39m\u001b[34m(self, images, task_names, det_predictor, detection_batch_size, recognition_batch_size, highres_images, bboxes, polygons, input_text, sort_lines, math_mode, return_words, drop_repeated_text, max_sliding_window, max_tokens, filter_tag_list)\u001b[39m\n\u001b[32m    428\u001b[39m flat[\u001b[33m\"\u001b[39m\u001b[33mtask_names\u001b[39m\u001b[33m\"\u001b[39m] = [flat[\u001b[33m\"\u001b[39m\u001b[33mtask_names\u001b[39m\u001b[33m\"\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices]\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m predicted_tokens, batch_bboxes, scores, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfoundation_predictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprediction_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mslices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtask_names\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrecognition_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmath_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmath_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_repeated_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_lookahead_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfoundation_predictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmulti_output_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_sliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_sliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtqdm_desc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRecognizing Text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    442\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# Get text and bboxes in structured form\u001b[39;00m\n\u001b[32m    445\u001b[39m bbox_size = \u001b[38;5;28mself\u001b[39m.bbox_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\foundation\\__init__.py:827\u001b[39m, in \u001b[36mFoundationPredictor.prediction_loop\u001b[39m\u001b[34m(self, images, input_texts, task_names, batch_size, max_tokens, max_sliding_window, math_mode, drop_repeated_tokens, max_lookahead_tokens, top_k, tqdm_desc)\u001b[39m\n\u001b[32m    825\u001b[39m                     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m     updated_inputs, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcurrent_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lookahead_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_lookahead_tokens\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    830\u001b[39m     mark_step()\n\u001b[32m    832\u001b[39m     predicted_tokens_cpu = outputs.preds.cpu()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\foundation\\__init__.py:341\u001b[39m, in \u001b[36mFoundationPredictor.decode\u001b[39m\u001b[34m(self, current_inputs, max_lookahead_tokens)\u001b[39m\n\u001b[32m    337\u001b[39m cache_position = \u001b[38;5;28mself\u001b[39m.get_cache_position(\n\u001b[32m    338\u001b[39m     input_ids.shape[\u001b[32m1\u001b[39m], \u001b[38;5;28mself\u001b[39m.kv_cache.attention_mask, prefill=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    339\u001b[39m )\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m settings.INFERENCE_MODE():\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_boxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m        \u001b[49m\u001b[43membed_boxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43membed_boxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    355\u001b[39m processed_output: ContinuousBatchOutput = \u001b[38;5;28mself\u001b[39m.process_outputs(\n\u001b[32m    356\u001b[39m     outputs, max_lookahead_tokens=max_lookahead_tokens\n\u001b[32m    357\u001b[39m )\n\u001b[32m    359\u001b[39m input_ids = processed_output.input_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\common\\surya\\__init__.py:468\u001b[39m, in \u001b[36mSuryaModel.forward\u001b[39m\u001b[34m(self, input_ids, image_embeddings, labels, image_tiles, grid_thw, inputs_embeds, attention_mask, position_ids, cache_position, past_key_values, output_hidden_states, output_attentions, use_cache, encoder_chunk_size, cache_idxs, num_valid_tokens, prefill, text_lengths, valid_batch_size, input_boxes, embed_boxes, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    459\u001b[39m causal_mask = \u001b[38;5;28mself\u001b[39m._update_causal_mask(\n\u001b[32m    460\u001b[39m     attention_mask,\n\u001b[32m    461\u001b[39m     inputs_embeds,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     output_attentions,\n\u001b[32m    465\u001b[39m )\n\u001b[32m    467\u001b[39m attention_mask = causal_mask\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logits_to_keep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\common\\surya\\decoder\\__init__.py:504\u001b[39m, in \u001b[36mSuryaDecoderModel.forward\u001b[39m\u001b[34m(self, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, cache_idxs, num_valid_tokens, text_lengths, prefill, **flash_attn_kwargs)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;66;03m# decoder layers\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_idxs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_valid_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    522\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\common\\surya\\decoder\\__init__.py:322\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, cache_idxs, num_valid_tokens, text_lengths, prefill, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m residual = hidden_states\n\u001b[32m    321\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    325\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\surya\\common\\surya\\decoder\\__init__.py:40\u001b[39m, in \u001b[36mQwen2MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) * \u001b[38;5;28mself\u001b[39m.up_proj(x))\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\llmserver\\miniconda3\\envs\\article\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from paperflow import PaperPipeline\n",
    "\n",
    "# Configuration\n",
    "USE_GPU = False  # Set to True if you have CUDA GPU and want faster extraction\n",
    "PDF_DIR = './test_pdfs'\n",
    "\n",
    "# Choose PDF extraction backend:\n",
    "# - \"auto\": Try marker â†’ docling â†’ markitdown (recommended)\n",
    "# - \"marker\": High quality, best for academic papers, GPU support\n",
    "# - \"docling\": Good table/figure extraction, IBM, GPU support  \n",
    "# - \"markitdown\": Lightweight, fast, CPU only, Microsoft\n",
    "EXTRACTION_BACKEND = \"auto\"\n",
    "\n",
    "print(f\"GPU acceleration: {'Enabled' if USE_GPU else 'Disabled'}\")\n",
    "print(f\"PDF directory: {PDF_DIR}\")\n",
    "print(f\"Extraction backend: {EXTRACTION_BACKEND}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6b5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperflow import PaperPipeline\n",
    "\n",
    "# Create pipeline with selected backend\n",
    "pipeline = PaperPipeline(\n",
    "    gpu=USE_GPU, \n",
    "    pdf_dir=PDF_DIR,\n",
    "    extraction_backend=EXTRACTION_BACKEND\n",
    ")\n",
    "\n",
    "print(f\"âœ… Pipeline created with {pipeline._extractor.active_backend} backend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0489e54f",
   "metadata": {},
   "source": [
    "## 1. arXiv Provider Demo\n",
    "\n",
    "Search for computer science papers on arXiv, the preprint server for physics, mathematics, computer science, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f501e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search arXiv\n",
    "print('ðŸ” Searching arXiv for \"transformer attention\" papers...')\n",
    "results = pipeline.search('transformer attention mechanism', sources=['arxiv'], max_results=3)\n",
    "\n",
    "print(f\"âœ… Found {results.total_found} papers in {results.search_time_ms}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display arXiv results\n",
    "if results.papers:\n",
    "    print(\"\\nðŸ“‹ arXiv Search Results:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, paper in enumerate(results.papers, 1):\n",
    "        title = paper['title'][:70] + \"...\" if len(paper['title']) > 70 else paper['title']\n",
    "        authors = \", \".join([a['name'] for a in paper.get('authors', [])[:2]])\n",
    "        if len(paper.get('authors', [])) > 2:\n",
    "            authors += \" et al.\"\n",
    "        \n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Authors: {authors}\")\n",
    "        print(f\"   Year: {paper.get('year', 'N/A')}\")\n",
    "        print(f\"   arXiv ID: {paper.get('arxiv_id', 'N/A')}\")\n",
    "        print(f\"   Citations: {paper.get('citation_count', 0)}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"âŒ No papers found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af67a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display arXiv results in JSON format\n",
    "if results.papers:\n",
    "    import json\n",
    "    print(\"ðŸ“‹ arXiv Search Results in JSON:\")\n",
    "    print(json.dumps(results.papers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de67cf",
   "metadata": {},
   "source": [
    "## 2. PubMed Provider Demo\n",
    "\n",
    "Search for biomedical research papers in PubMed, the premier database for biomedical literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search PubMed\n",
    "print('ðŸ” Searching PubMed for \"CRISPR gene editing\" papers...')\n",
    "pubmed_results = pipeline.search('CRISPR gene editing therapy', sources=['pubmed'], max_results=3)\n",
    "\n",
    "print(f\"âœ… Found {pubmed_results.total_found} papers in {pubmed_results.search_time_ms}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80719270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PubMed results\n",
    "if pubmed_results.papers:\n",
    "    print(\"\\nðŸ“‹ PubMed Search Results:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, paper in enumerate(pubmed_results.papers, 1):\n",
    "        title = paper['title'][:70] + \"...\" if len(paper['title']) > 70 else paper['title']\n",
    "        authors = \", \".join([a['name'] for a in paper.get('authors', [])[:2]])\n",
    "        if len(paper.get('authors', [])) > 2:\n",
    "            authors += \" et al.\"\n",
    "        \n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Authors: {authors}\")\n",
    "        print(f\"   Year: {paper.get('year', 'N/A')}\")\n",
    "        print(f\"   DOI: {paper.get('doi', 'N/A')}\")\n",
    "        print(f\"   Citations: {paper.get('citation_count', 0)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PubMed results in JSON format\n",
    "if pubmed_results.papers:\n",
    "    import json\n",
    "    print(\"ðŸ“‹ PubMed Search Results in JSON:\")\n",
    "    print(json.dumps(pubmed_results.papers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c791a8f8",
   "metadata": {},
   "source": [
    "## 3. Semantic Scholar Provider Demo\n",
    "\n",
    "Search using Semantic Scholar's AI-powered academic search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4df0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Semantic Scholar\n",
    "print('ðŸ” Searching Semantic Scholar for \"large language models\"...')\n",
    "sem_results = pipeline.search('large language models GPT', sources=['semantic_scholar'], max_results=3)\n",
    "\n",
    "print(f\"âœ… Found {sem_results.total_found} papers in {sem_results.search_time_ms}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac032dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Semantic Scholar results\n",
    "if sem_results.papers:\n",
    "    print(\"\\nðŸ“‹ Semantic Scholar Results:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, paper in enumerate(sem_results.papers, 1):\n",
    "        title = paper['title'][:70] + \"...\" if len(paper['title']) > 70 else paper['title']\n",
    "        authors = \", \".join([a['name'] for a in paper.get('authors', [])[:2]])\n",
    "        if len(paper.get('authors', [])) > 2:\n",
    "            authors += \" et al.\"\n",
    "        \n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Authors: {authors}\")\n",
    "        print(f\"   Year: {paper.get('year', 'N/A')}\")\n",
    "        print(f\"   DOI: {paper.get('doi', 'N/A')}\")\n",
    "        print(f\"   Citations: {paper.get('citation_count', 0)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800919bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Semantic Scholar results in JSON format\n",
    "if sem_results.papers:\n",
    "    import json\n",
    "    print(\"ðŸ“‹ Semantic Scholar Search Results in JSON:\")\n",
    "    print(json.dumps(sem_results.papers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a66d8",
   "metadata": {},
   "source": [
    "## 4. OpenAlex Provider Demo\n",
    "\n",
    "Search the OpenAlex catalog, which covers millions of scholarly works from all disciplines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1483d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search OpenAlex\n",
    "print('ðŸ” Searching OpenAlex for \"climate change adaptation\"...')\n",
    "openalex_results = pipeline.search('climate change adaptation strategies', sources=['openalex'], max_results=3)\n",
    "\n",
    "print(f\"âœ… Found {openalex_results.total_found} papers in {openalex_results.search_time_ms}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88008867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display OpenAlex results\n",
    "if openalex_results.papers:\n",
    "    print(\"\\nðŸ“‹ OpenAlex Results:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, paper in enumerate(openalex_results.papers, 1):\n",
    "        title = paper['title'][:70] + \"...\" if len(paper['title']) > 70 else paper['title']\n",
    "        authors = \", \".join([a['name'] for a in paper.get('authors', [])[:2]])\n",
    "        if len(paper.get('authors', [])) > 2:\n",
    "            authors += \" et al.\"\n",
    "        \n",
    "        print(f\"{i}. {title}\")\n",
    "        print(f\"   Authors: {authors}\")\n",
    "        print(f\"   Year: {paper.get('year', 'N/A')}\")\n",
    "        print(f\"   DOI: {paper.get('doi', 'N/A')}\")\n",
    "        print(f\"   Citations: {paper.get('citation_count', 0)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5fb586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display OpenAlex results in JSON format\n",
    "if openalex_results.papers:\n",
    "    import json\n",
    "    print(\"ðŸ“‹ OpenAlex Search Results in JSON:\")\n",
    "    print(json.dumps(openalex_results.papers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbdbef",
   "metadata": {},
   "source": [
    "## 5. Complete Pipeline Demo\n",
    "\n",
    "Demonstrate the full pipeline: search â†’ download â†’ extract â†’ chunk â†’ embed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e62b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full pipeline demonstration\n",
    "print(\"ðŸš€ Running complete pipeline...\")\n",
    "\n",
    "# 1. Search\n",
    "print(\"1. Searching for papers...\")\n",
    "search_results = pipeline.search(\"neural networks\", sources=[\"arxiv\"], max_results=1)\n",
    "\n",
    "if search_results.papers:\n",
    "    paper_dict = search_results.papers[0]\n",
    "    \n",
    "    # 2. Download\n",
    "    print(\"2. Downloading PDF...\")\n",
    "    paper = pipeline.download(paper_dict)\n",
    "    \n",
    "    # 3. Extract\n",
    "    print(\"3. Extracting content...\")\n",
    "    paper = pipeline.extract(paper)\n",
    "    \n",
    "    # 4. Chunk\n",
    "    print(\"4. Creating chunks...\")\n",
    "    paper = pipeline.chunk(paper)\n",
    "    \n",
    "    # 5. Embed (if embeddings available)\n",
    "    print(\"5. Creating embeddings...\")\n",
    "    try:\n",
    "        paper = pipeline.embed(paper)\n",
    "        print(\"âœ… Pipeline completed successfully!\")\n",
    "        \n",
    "        # Show results\n",
    "        print(f\"\\nðŸ“Š Results:\")\n",
    "        print(f\"Title: {paper.metadata.title[:50]}...\")\n",
    "        print(f\"Sections: {len(paper.sections)}\")\n",
    "        print(f\"Chunks: {len(paper.chunks)}\")\n",
    "        print(f\"Has embeddings: {paper.has_embeddings}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Embedding failed (missing dependencies): {e}\")\n",
    "        print(\"âœ… Pipeline completed (without embeddings)\")\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Results:\")\n",
    "        print(f\"Title: {paper.metadata.title[:50]}...\")\n",
    "        print(f\"Sections: {len(paper.sections)}\")\n",
    "        print(f\"Chunks: {len(paper.chunks)}\")\n",
    "else:\n",
    "    print(\"âŒ No papers found for pipeline demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36f99ea",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "âœ… **All 4 academic providers**: arXiv, PubMed, Semantic Scholar, OpenAlex  \n",
    "âœ… **Search across all sources** with formatted and JSON output  \n",
    "âœ… **Complete processing pipeline**: search â†’ download â†’ extract â†’ chunk â†’ embed  \n",
    "âœ… **PDF extraction backends**: Marker AI, Docling, MarkItDown with auto-fallback  \n",
    "âœ… **GPU acceleration** support for faster processing  \n",
    "\n",
    "### Key Features Used:\n",
    "- Unified search interface across all providers\n",
    "- Automatic PDF downloading and text extraction\n",
    "- Intelligent text chunking for RAG\n",
    "- Vector embeddings for semantic search\n",
    "- Tabular and JSON result display\n",
    "- Error handling and graceful fallbacks\n",
    "\n",
    "Happy researching! ðŸ”¬ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6287c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Display results in JSON format\n",
    "print(\"Search Results in JSON:\")\n",
    "print(json.dumps(results.papers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edabf78a",
   "metadata": {},
   "source": [
    "## What Happens Next?\n",
    "\n",
    "After processing, you can:\n",
    "\n",
    "- **Query the papers**: Use RAG to ask questions about the content\n",
    "- **Export to LangChain**: Get LangChain documents for further processing\n",
    "- **Save to vector database**: Store embeddings for semantic search\n",
    "- **Analyze content**: Access extracted sections, chunks, and metadata\n",
    "\n",
    "## Command Line Usage\n",
    "\n",
    "You can also use paperflow from the command line:\n",
    "\n",
    "```bash\n",
    "# Install with CLI support\n",
    "pip install paperflow\n",
    "\n",
    "# Search and display results\n",
    "paperflow \"transformer attention\" --sources arxiv --max-results 5\n",
    "```\n",
    "\n",
    "## Advanced Usage\n",
    "\n",
    "For more advanced features, install optional dependencies:\n",
    "\n",
    "```bash\n",
    "pip install paperflow[all]  # Full installation\n",
    "pip install paperflow[extraction]  # PDF extraction only\n",
    "pip install paperflow[rag]  # RAG features only\n",
    "```\n",
    "\n",
    "Check out the [documentation](https://github.com/osllmai/paperflow) for more examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperflow import PaperPipeline\n",
    "\n",
    "# Configuration\n",
    "USE_GPU = False  # Set to True if you have CUDA GPU and want faster extraction\n",
    "PDF_DIR = './test_pdfs'\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = PaperPipeline(gpu=USE_GPU, pdf_dir=PDF_DIR)\n",
    "\n",
    "# Search for papers\n",
    "print('Searching for papers on transformers...')\n",
    "results = pipeline.search('transformer attention', sources=['arxiv'], max_results=3)\n",
    "\n",
    "# Display results\n",
    "print(results)\n",
    "print()\n",
    "\n",
    "# Process all papers\n",
    "print('Processing all papers...')\n",
    "for i, paper_meta in enumerate(results.papers, 1):\n",
    "    print(f'Processing paper {i}: {paper_meta[\"title\"][:50]}...')\n",
    "    paper = pipeline.process(paper_meta)\n",
    "    print(f'  - PDF saved: {paper.pdf_path}')\n",
    "    print(f'  - Sections: {len(paper.sections)}, Chunks: {len(paper.chunks)}')\n",
    "    print()\n",
    "\n",
    "print('All done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "article",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
